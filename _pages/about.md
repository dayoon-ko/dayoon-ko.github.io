---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<p style="font-size:15px;">Hi! I'm Dayoon Ko, a Ph.D. student in CSE at Seoul National university, advised by Gunhee Kim. My primary research interest lies in model evaluation for several challenges.  My research has focused on retrieval-augmented generation (RAG) and multimodal learning, emphasizing enhancing the scalability and adaptability of large language models (LLMs). Moving forward, I aim to apply RAG techniques to video-based LLMs, exploring how these models can integrate and process both text and video data for more effective understanding and generation.</p>

Recent News!
======
<p style="font-size:15px;">Our paper "DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG" was accepted in EMNLP 2024 Main!</p>

Publications
======
<h5 style="margin-top:0px">DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG</h5>
<div class="pub_item" style="display: inline-flex; padding-bottom:20px;">
  <div class="pub_img" style="height:200px; width:200px; object-fit:cover;">
    <img src="https://dayoon-ko.github.io/images/dynamicer.png" alt="">
  </div>
  <div class="pub_detail" style="margin-left:10px; width:400px">
    <p style="font-size:15px; margin-bottom:2px">Jinyoung Kim, <b>Dayoon Ko</b>, Gunhee Kim</p>
    <p style="font-size:15px; margin-bottom:2px">EMNLP 2024</p>
    <p style="font-size:15px; margin-bottom:2px">This work addresses challenges in resolving temporally evolving mentions to entities. Resolving mentions is key to improve retrieval, enhancing RAG accuracy in dynamic environments.</p>
  </div>
</div>

<h5 style="margin-top:0px">GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge?</h5>
<div class="pub_item" style="display: inline-flex; padding-bottom:20px;">
  <div class="pub_img" style="height:200px; width:200px; object-fit:cover;">
    <img src="https://dayoon-ko.github.io/images/growover.png" alt="">
  </div>
  <div class="pub_detail" style="margin-left:10px; width:400px">
    <p style="font-size:15px; margin-bottom:2px"><b>Dayoon Ko</b>, Jinyoung Kim, Hahyeon Choi, Gunhee Kim</p>
    <p style="font-size:15px; margin-bottom:2px">ACL 2024</p>
    <p style="font-size:15px; margin-bottom:2px">We propose continually updated QA & dialogue benchmark to evaluate whether LLM can handle dynamic knowledge. We train a classifier using the last hidden state of the LLM to assess its confience, enabling RAG systems to adapt to new knowledge without retraining.</p>
  </div>
</div>

<h5 style="margin-top:0px">Can Language Models Laugh at YouTube Short-form Videos?</h5>
<div class="pub_item" style="display: inline-flex; padding-bottom:20px;">
  <div class="pub_img" style="height:200px; width:200px; object-fit:cover;">
    <img src="https://dayoon-ko.github.io/images/exfuntube.png" alt="">
  </div>
  <div class="pub_detail" style="margin-left:10px; width:400px">
    <p style="margin-bottom:2px"><b>Dayoon Ko</b>, Sangho Lee, Gunhee Kim</p>
    <p style="margin-bottom:2px">EMNLP 2023</p>
    <p style="margin-bottom:2px">This work addresses challenges in resolving temporally evolving mentions to entities. Resolving mentions is key to improve retrieval, enhancing RAG accuracy in dynamic environments.</p>
  </div>
</div>

Education
======
<p style="margin-bottom:2px">M.S/Ph.D in Computer Science Engineering (2022.9 - )</p>
* Seoul National University
* Advisor: Gunhee Kim

<p style="margin-bottom:2px">B.S. in Computer Science Engineering (2018.3 - 2022.8)</p>
* Yonsei University
* GPA: 4.12/4.30 (Rank: 1/28)
